{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext blackcellmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-04-11T23:02:42.759Z",
     "iopub.status.busy": "2020-04-11T23:02:42.689Z",
     "iopub.status.idle": "2020-04-11T23:02:52.706Z",
     "shell.execute_reply": "2020-04-11T23:02:52.781Z"
    }
   },
   "outputs": [],
   "source": [
    "from prefect import Flow, Parameter, unmapped\n",
    "import pandas as pd\n",
    "from prefect.engine.executors import DaskExecutor\n",
    "from meta_model import MetaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = pd.read_csv(\"../data/titanic/train.csv\")\n",
    "test= pd.read_csv(\"../data/titanic/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ml_flow import *\n",
    "\n",
    "with Flow(\"data_cleaning\") as flow:\n",
    "    input_data = Parameter(\"input_data\")\n",
    "    problem, target, features = (\n",
    "        Parameter(\"problem\"),\n",
    "        Parameter(\"target\"),\n",
    "        Parameter(\"features\"),\n",
    "    )\n",
    "    tinydb = recreate_tinydb()\n",
    "    nan_features = extract_nan_features(input_data)\n",
    "    problematic_features = extract_problematic_features(input_data)\n",
    "    undefined_features = extract_undefined_features(\n",
    "        input_data, features, target, nan_features, problematic_features\n",
    "    )\n",
    "    input_data_with_missing = fit_transform_missing_indicator(\n",
    "        input_data, undefined_features\n",
    "    )\n",
    "\n",
    "    train_valid_split = extract_train_valid_split(\n",
    "        input_data=input_data_with_missing, problem=problem, target=target\n",
    "    )\n",
    "    train_data = extract_train_data(train_valid_split)\n",
    "    valid_data = extract_valid_data(train_valid_split)\n",
    "    numeric_features = extract_numeric_features(input_data, undefined_features)\n",
    "    categorical_features = extract_categorical_features(input_data, undefined_features)\n",
    "\n",
    "    # numeric columns work\n",
    "    numeric_imputer = fit_numeric_imputer(train_data, numeric_features)\n",
    "    imputed_train_numeric_df = impute_numeric_df(\n",
    "        numeric_imputer, train_data, numeric_features\n",
    "    )\n",
    "    imputed_valid_numeric_df = impute_numeric_df(\n",
    "        numeric_imputer, valid_data, numeric_features\n",
    "    )\n",
    "\n",
    "    yeo_johnson_transformer = fit_yeo_johnson_transformer(imputed_train_numeric_df)\n",
    "    yeo_johnson_train_transformed = transform_yeo_johnson_transformer(\n",
    "        imputed_train_numeric_df, yeo_johnson_transformer\n",
    "    )\n",
    "    yeo_johnson_valid_transformed = transform_yeo_johnson_transformer(\n",
    "        imputed_valid_numeric_df, yeo_johnson_transformer\n",
    "    )\n",
    "\n",
    "    # categorical columns work\n",
    "    categorical_imputer = fit_categorical_imputer(train_data, categorical_features)\n",
    "    imputed_train_categorical_df = transform_categorical_data(\n",
    "        train_data, categorical_features, categorical_imputer\n",
    "    )\n",
    "    imputed_valid_categorical_df = transform_categorical_data(\n",
    "        valid_data, categorical_features, categorical_imputer\n",
    "    )\n",
    "\n",
    "    target_transformer = fit_target_transformer(problem, target, train_data)\n",
    "    transformed_train_target = transform_target(\n",
    "        problem, target, train_data, target_transformer\n",
    "    )\n",
    "    transformed_valid_target = transform_target(\n",
    "        problem, target, valid_data, target_transformer\n",
    "    )\n",
    "\n",
    "    target_encoder_transformer = fit_target_encoder(\n",
    "        imputed_train_categorical_df, transformed_train_target\n",
    "    )\n",
    "    target_encoded_train_df = target_encoder_transform(\n",
    "        target_encoder_transformer, imputed_train_categorical_df\n",
    "    )\n",
    "    target_encoded_valid_df = target_encoder_transform(\n",
    "        target_encoder_transformer, imputed_valid_categorical_df\n",
    "    )\n",
    "\n",
    "    # merge_data\n",
    "    transformed_train_df = merge_transformed_data(\n",
    "        target_encoded_train_df, yeo_johnson_train_transformed,\n",
    "    )\n",
    "    transformed_valid_df = merge_transformed_data(\n",
    "        target_encoded_valid_df, yeo_johnson_valid_transformed,\n",
    "    )\n",
    "\n",
    "    # outlierness\n",
    "    hbos_transformer = fit_hbos_transformer(transformed_train_df)\n",
    "    hbos_transform_train_data = hbos_transform(transformed_train_df, hbos_transformer)\n",
    "    hbos_transform_valid_data = hbos_transform(transformed_valid_df, hbos_transformer)\n",
    "\n",
    "    # merge outlierness\n",
    "    transformed_train_df = merge_hbos_df(\n",
    "        transformed_train_df, hbos_transform_train_data\n",
    "    )\n",
    "    transformed_valid_df = merge_hbos_df(\n",
    "        transformed_valid_df, hbos_transform_valid_data\n",
    "    )\n",
    "    save_data(transformed_train_df, \"transformed_train.df\",)\n",
    "    save_data(transformed_valid_df, \"transformed_valid.df\",)\n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-04-12 23:23:26,649] INFO - prefect.FlowRunner | Beginning Flow run for 'data_cleaning'\n",
      "[2020-04-12 23:23:26,653] INFO - prefect.FlowRunner | Starting flow run.\n",
      "[2020-04-12 23:23:26,821] INFO - prefect.TaskRunner | Task 'input_data': Starting task run...\n",
      "[2020-04-12 23:23:26,852] INFO - prefect.TaskRunner | Task 'recreate_tinydb': Starting task run...\n",
      "[2020-04-12 23:23:26,868] INFO - prefect.TaskRunner | Task 'input_data': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:23:26,956] INFO - prefect.TaskRunner | Task 'features': Starting task run...\n",
      "[2020-04-12 23:23:26,963] INFO - prefect.TaskRunner | Task 'target': Starting task run...\n",
      "[2020-04-12 23:23:26,986] INFO - prefect.TaskRunner | Task 'problem': Starting task run...\n",
      "[2020-04-12 23:23:26,987] INFO - prefect.TaskRunner | Task 'features': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:23:27,011] INFO - prefect.TaskRunner | Task 'extract_problematic_features': Starting task run...\n",
      "[2020-04-12 23:23:27,019] INFO - prefect.TaskRunner | Task 'extract_nan_features': Starting task run...\n",
      "[2020-04-12 23:23:27,026] INFO - prefect.TaskRunner | Task 'target': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:23:27,034] INFO - prefect.TaskRunner | Task 'problem': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:23:27,053] INFO - prefect.TaskRunner | Task 'extract_problematic_features': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:23:27,054] INFO - prefect.TaskRunner | Task 'extract_nan_features': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:23:27,074] INFO - prefect.TaskRunner | Task 'extract_undefined_features': Starting task run...\n",
      "[2020-04-12 23:23:27,081] INFO - prefect.TaskRunner | Task 'extract_undefined_features': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:23:27,115] INFO - prefect.TaskRunner | Task 'extract_categorical_features': Starting task run...\n",
      "[2020-04-12 23:23:27,119] INFO - prefect.TaskRunner | Task 'extract_numeric_features': Starting task run...\n",
      "[2020-04-12 23:23:27,216] INFO - prefect.TaskRunner | Task 'recreate_tinydb': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:23:27,262] INFO - prefect.TaskRunner | Task 'fit_transform_missing_indicator': Starting task run...\n",
      "[2020-04-12 23:23:27,271] INFO - prefect.TaskRunner | Task 'extract_categorical_features': finished task run for task with final state: 'Success'\n",
      "['Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Embarked']\n",
      "[3 8]\n",
      "['missing_Age', 'missing_Embarked']\n",
      "[2020-04-12 23:23:27,286] INFO - prefect.TaskRunner | Task 'extract_numeric_features': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:23:27,297] INFO - prefect.TaskRunner | Task 'fit_transform_missing_indicator': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:23:27,313] INFO - prefect.TaskRunner | Task 'extract_train_valid_split': Starting task run...\n",
      "[2020-04-12 23:23:27,322] INFO - prefect.TaskRunner | Task 'extract_train_valid_split': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:23:27,339] INFO - prefect.TaskRunner | Task 'extract_train_data': Starting task run...\n",
      "[2020-04-12 23:23:27,358] INFO - prefect.TaskRunner | Task 'extract_valid_data': Starting task run...\n",
      "[2020-04-12 23:23:27,359] INFO - prefect.TaskRunner | Task 'extract_train_data': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:23:27,366] INFO - prefect.TaskRunner | Task 'extract_valid_data': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:23:27,397] INFO - prefect.TaskRunner | Task 'fit_numeric_imputer': Starting task run...\n",
      "[2020-04-12 23:23:27,398] INFO - prefect.TaskRunner | Task 'fit_categorical_imputer': Starting task run...\n",
      "[2020-04-12 23:23:27,411] INFO - prefect.TaskRunner | Task 'fit_target_transformer': Starting task run...\n",
      "[2020-04-12 23:23:27,420] INFO - prefect.TaskRunner | Task 'fit_numeric_imputer': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:23:27,432] INFO - prefect.TaskRunner | Task 'fit_target_transformer': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:23:27,456] INFO - prefect.TaskRunner | Task 'fit_categorical_imputer': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:23:27,464] INFO - prefect.TaskRunner | Task 'impute_numeric_df': Starting task run...\n",
      "[2020-04-12 23:23:27,470] INFO - prefect.TaskRunner | Task 'impute_numeric_df': Starting task run...\n",
      "[2020-04-12 23:23:27,515] INFO - prefect.TaskRunner | Task 'transform_target': Starting task run...\n",
      "[2020-04-12 23:23:27,522] INFO - prefect.TaskRunner | Task 'transform_categorical_data': Starting task run...\n",
      "[2020-04-12 23:23:27,528] INFO - prefect.TaskRunner | Task 'transform_categorical_data': Starting task run...\n",
      "[2020-04-12 23:23:27,530] INFO - prefect.TaskRunner | Task 'transform_target': Starting task run...\n",
      "[2020-04-12 23:23:27,538] INFO - prefect.TaskRunner | Task 'impute_numeric_df': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:23:27,547] INFO - prefect.TaskRunner | Task 'impute_numeric_df': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:23:27,553] INFO - prefect.TaskRunner | Task 'transform_target': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:23:27,563] INFO - prefect.TaskRunner | Task 'transform_categorical_data': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:23:27,577] INFO - prefect.TaskRunner | Task 'transform_categorical_data': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:23:27,579] INFO - prefect.TaskRunner | Task 'transform_target': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:23:27,596] INFO - prefect.TaskRunner | Task 'fit_yeo_johnson_transformer': Starting task run...\n",
      "[2020-04-12 23:23:27,622] INFO - prefect.TaskRunner | Task 'fit_target_encoder': Starting task run...\n",
      "[2020-04-12 23:23:27,665] INFO - prefect.TaskRunner | Task 'fit_yeo_johnson_transformer': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:23:27,734] INFO - prefect.TaskRunner | Task 'transform_yeo_johnson_transformer': Starting task run...\n",
      "[2020-04-12 23:23:27,735] INFO - prefect.TaskRunner | Task 'transform_yeo_johnson_transformer': Starting task run...\n",
      "[2020-04-12 23:23:27,750] INFO - prefect.TaskRunner | Task 'transform_yeo_johnson_transformer': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:23:27,758] INFO - prefect.TaskRunner | Task 'transform_yeo_johnson_transformer': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:23:27,768] INFO - prefect.TaskRunner | Task 'fit_target_encoder': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:23:27,799] INFO - prefect.TaskRunner | Task 'target_encoder_transform': Starting task run...\n",
      "[2020-04-12 23:23:27,799] INFO - prefect.TaskRunner | Task 'target_encoder_transform': Starting task run...\n",
      "[2020-04-12 23:23:27,821] INFO - prefect.TaskRunner | Task 'target_encoder_transform': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:23:27,847] INFO - prefect.TaskRunner | Task 'target_encoder_transform': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:23:27,854] INFO - prefect.TaskRunner | Task 'merge_transformed_data': Starting task run...\n",
      "[2020-04-12 23:23:27,871] INFO - prefect.TaskRunner | Task 'merge_transformed_data': Starting task run...\n",
      "[2020-04-12 23:23:27,878] INFO - prefect.TaskRunner | Task 'merge_transformed_data': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:23:27,890] INFO - prefect.TaskRunner | Task 'merge_transformed_data': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:23:27,902] INFO - prefect.TaskRunner | Task 'fit_hbos_transformer': Starting task run...\n",
      "[2020-04-12 23:23:29,199] INFO - prefect.TaskRunner | Task 'fit_hbos_transformer': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:23:29,218] INFO - prefect.TaskRunner | Task 'hbos_transform': Starting task run...\n",
      "[2020-04-12 23:23:29,229] INFO - prefect.TaskRunner | Task 'hbos_transform': Starting task run...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-04-12 23:23:29,237] INFO - prefect.TaskRunner | Task 'hbos_transform': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:23:29,246] INFO - prefect.TaskRunner | Task 'hbos_transform': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:23:29,266] INFO - prefect.TaskRunner | Task 'merge_hbos_df': Starting task run...\n",
      "[2020-04-12 23:23:29,285] INFO - prefect.TaskRunner | Task 'merge_hbos_df': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:23:29,287] INFO - prefect.TaskRunner | Task 'merge_hbos_df': Starting task run...\n",
      "[2020-04-12 23:23:29,304] INFO - prefect.TaskRunner | Task 'merge_hbos_df': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:23:29,311] INFO - prefect.TaskRunner | Task 'save_data': Starting task run...\n",
      "[2020-04-12 23:23:29,341] INFO - prefect.TaskRunner | Task 'save_data': Starting task run...\n",
      "[2020-04-12 23:23:29,348] INFO - prefect.TaskRunner | Task 'fit_model': Starting task run...\n",
      "[2020-04-12 23:23:29,354] INFO - prefect.TaskRunner | Task 'fit_svd': Starting task run...\n",
      "[2020-04-12 23:23:29,403] INFO - prefect.TaskRunner | Task 'save_data': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:23:29,410] INFO - prefect.TaskRunner | Task 'save_data': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:23:29,425] INFO - prefect.TaskRunner | Task 'fit_svd': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:23:29,491] INFO - prefect.TaskRunner | Task 'fit_model[1]': Starting task run...\n",
      "[2020-04-12 23:23:29,515] INFO - prefect.TaskRunner | Task 'fit_model[3]': Starting task run...\n",
      "[2020-04-12 23:23:29,516] INFO - prefect.TaskRunner | Task 'fit_model[2]': Starting task run...\n",
      "[2020-04-12 23:23:29,522] INFO - prefect.TaskRunner | Task 'fit_model[4]': Starting task run...\n",
      "[2020-04-12 23:23:29,529] INFO - prefect.TaskRunner | Task 'fit_model[0]': Starting task run...\n",
      "[2020-04-12 23:23:29,537] INFO - prefect.TaskRunner | Task 'fit_model[5]': Starting task run...\n",
      "[2020-04-12 23:23:29,547] INFO - prefect.TaskRunner | Task 'fit_model[1]': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:23:29,557] INFO - prefect.TaskRunner | Task 'fit_model[2]': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:23:29,565] INFO - prefect.TaskRunner | Task 'fit_model[4]': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:23:29,571] INFO - prefect.TaskRunner | Task 'fit_model[3]': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:23:29,580] INFO - prefect.TaskRunner | Task 'fit_model[0]': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:23:29,613] INFO - prefect.TaskRunner | Task 'fit_model[6]': Starting task run...\n",
      "[2020-04-12 23:23:29,619] INFO - prefect.TaskRunner | Task 'svd_transform': Starting task run...\n",
      "[2020-04-12 23:23:29,635] INFO - prefect.TaskRunner | Task 'svd_transform': Starting task run...\n",
      "[2020-04-12 23:23:29,703] INFO - prefect.TaskRunner | Task 'svd_transform': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:23:29,723] INFO - prefect.TaskRunner | Task 'svd_transform': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:23:29,759] INFO - prefect.TaskRunner | Task 'fit_model[5]': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:23:29,806] INFO - prefect.TaskRunner | Task 'fit_model[6]': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:23:29,819] INFO - prefect.TaskRunner | Task 'fit_model': finished task run for task with final state: 'Mapped'\n",
      "[2020-04-12 23:23:29,842] INFO - prefect.TaskRunner | Task 'predict_model': Starting task run...\n",
      "[2020-04-12 23:23:29,926] INFO - prefect.TaskRunner | Task 'predict_model[1]': Starting task run...\n",
      "[2020-04-12 23:23:29,961] INFO - prefect.TaskRunner | Task 'predict_model[0]': Starting task run...\n",
      "[2020-04-12 23:23:29,962] INFO - prefect.TaskRunner | Task 'predict_model[2]': Starting task run...\n",
      "[2020-04-12 23:23:29,964] INFO - prefect.TaskRunner | Task 'predict_model[3]': Starting task run...\n",
      "[2020-04-12 23:23:29,964] INFO - prefect.TaskRunner | Task 'predict_model[4]': Starting task run...\n",
      "[2020-04-12 23:23:29,976] INFO - prefect.TaskRunner | Task 'predict_model[5]': Starting task run...\n",
      "[2020-04-12 23:23:29,978] INFO - prefect.TaskRunner | Task 'predict_model[1]': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:23:29,988] INFO - prefect.TaskRunner | Task 'predict_model[0]': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:23:29,995] INFO - prefect.TaskRunner | Task 'predict_model[2]': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:23:30,004] INFO - prefect.TaskRunner | Task 'predict_model[3]': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:23:30,012] INFO - prefect.TaskRunner | Task 'predict_model[4]': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:23:30,020] INFO - prefect.TaskRunner | Task 'predict_model[5]': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:23:30,042] INFO - prefect.TaskRunner | Task 'predict_model[6]': Starting task run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\projects\\crawto\\.venv\\lib\\site-packages\\distributed\\worker.py:3340: UserWarning: Large object of size 1.53 MB detected in task graph: \n",
      "  (None, 6, {<Edge (key=valid_data): merge_hbos_df t ...  succeeded.\">})\n",
      "Consider scattering large objects ahead of time\n",
      "with client.scatter to reduce scheduler burden and \n",
      "keep data on workers\n",
      "\n",
      "    future = client.submit(func, big_data)    # bad\n",
      "\n",
      "    big_future = client.scatter(big_data)     # good\n",
      "    future = client.submit(func, big_future)  # good\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-04-12 23:23:30,063] INFO - prefect.TaskRunner | Task 'predict_model[6]': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:23:30,076] INFO - prefect.TaskRunner | Task 'predict_model': finished task run for task with final state: 'Mapped'\n",
      "[2020-04-12 23:23:32,091] INFO - prefect.FlowRunner | Flow run SUCCESS: all reference tasks succeeded\n"
     ]
    }
   ],
   "source": [
    "executor = DaskExecutor()\n",
    "flow_state = flow.run(\n",
    "    input_data= input_df, \n",
    "    problem=\"binary classification\", \n",
    "    target = \"Survived\", \n",
    "    features = \"infer\",\n",
    "    executor=executor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Flow(\"data_visualization\") as flow:\n",
    "    transformed_train_df = pd.read_feather(\"transformed_train.df\")\n",
    "    transformed_valid_df = pd.read_feather(\"transformed_valid.df\")\n",
    "    svd = fit_svd(transformed_train_df)\n",
    "    svd_train = svd_transform(svd, transformed_train_df, \"transformed_train_df\",tinydb)\n",
    "    svd_valid = svd_transform(svd, transformed_valid_df, \"transformed_valid_df\",tinydb)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Flow(\"meta_model\") as flow:\n",
    "    transformed_train_df = pd.read_feather(\"transformed_train.df\")\n",
    "    transformed_valid_df = pd.read_feather(\"transformed_valid.df\")\n",
    "    \n",
    "    meta = MetaModel(problem=\"regression\", db=tinydb)\n",
    "    meta.default_models()\n",
    "    models = meta.models\n",
    "    fit_models = fit_model.map(\n",
    "        model=models,\n",
    "        train_data=unmapped(transformed_train_df),\n",
    "        target=unmapped(transformed_train_target),\n",
    "        problem=unmapped(problem),\n",
    "    )\n",
    "    predict_models = predict_model.map(\n",
    "        model=fit_models, valid_data=unmapped(transformed_valid_df),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#flow.visualize(flow_state=flow_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tinydb import TinyDB, Query\n",
    "db = TinyDB(\"db.json\")\n",
    "db.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = Query()\n",
    "r = db.search(q.chunk == \"svdname\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__and__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__invert__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__or__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_generate_test',\n",
       " '_path',\n",
       " '_prepare_test',\n",
       " '_test',\n",
       " 'all',\n",
       " 'any',\n",
       " 'exists',\n",
       " 'hashval',\n",
       " 'matches',\n",
       " 'one_of',\n",
       " 'search',\n",
       " 'test']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(q.chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "typing.Any"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flow._sorted_tasks()[38]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__and__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__floordiv__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__mifflin__',\n",
       " '__mod__',\n",
       " '__module__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__or__',\n",
       " '__pow__',\n",
       " '__radd__',\n",
       " '__rand__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rfloordiv__',\n",
       " '__rmod__',\n",
       " '__rmul__',\n",
       " '__ror__',\n",
       " '__rpow__',\n",
       " '__rsub__',\n",
       " '__rtruediv__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slotnames__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__truediv__',\n",
       " '__weakref__',\n",
       " 'auto_generated',\n",
       " 'bind',\n",
       " 'cache_for',\n",
       " 'cache_key',\n",
       " 'cache_validator',\n",
       " 'checkpoint',\n",
       " 'copy',\n",
       " 'inputs',\n",
       " 'is_equal',\n",
       " 'is_not_equal',\n",
       " 'log_stdout',\n",
       " 'logger',\n",
       " 'map',\n",
       " 'max_retries',\n",
       " 'name',\n",
       " 'not_',\n",
       " 'or_',\n",
       " 'outputs',\n",
       " 'result_handler',\n",
       " 'retry_delay',\n",
       " 'run',\n",
       " 'serialize',\n",
       " 'set_dependencies',\n",
       " 'set_downstream',\n",
       " 'set_upstream',\n",
       " 'skip_on_upstream_skip',\n",
       " 'slug',\n",
       " 'state_handlers',\n",
       " 'tags',\n",
       " 'timeout',\n",
       " 'trigger']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(flow._sorted_tasks()[38])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "nteract": {
   "version": "0.22.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
