{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext blackcellmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-04-11T23:02:42.759Z",
     "iopub.status.busy": "2020-04-11T23:02:42.689Z",
     "iopub.status.idle": "2020-04-11T23:02:52.706Z",
     "shell.execute_reply": "2020-04-11T23:02:52.781Z"
    }
   },
   "outputs": [],
   "source": [
    "from prefect import Flow, Parameter, unmapped\n",
    "import pandas as pd\n",
    "from prefect.engine.executors import DaskExecutor\n",
    "from meta_model import MetaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = pd.read_csv(\"../data/titanic/train.csv\")\n",
    "test= pd.read_csv(\"../data/titanic/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[2020-04-13 00:02:37,088] INFO - prefect.FlowRunner | Beginning Flow run for 'data_cleaning'\n[2020-04-13 00:02:37,093] INFO - prefect.FlowRunner | Starting flow run.\n[2020-04-13 00:02:37,182] INFO - prefect.TaskRunner | Task 'features': Starting task run...\n[2020-04-13 00:02:37,191] INFO - prefect.TaskRunner | Task 'input_data': Starting task run...\n[2020-04-13 00:02:37,210] INFO - prefect.TaskRunner | Task 'features': finished task run for task with final state: 'Success'\n[2020-04-13 00:02:37,245] INFO - prefect.TaskRunner | Task 'input_data': finished task run for task with final state: 'Success'\n[2020-04-13 00:02:37,291] INFO - prefect.TaskRunner | Task 'target': Starting task run...\n[2020-04-13 00:02:37,297] INFO - prefect.TaskRunner | Task 'recreate_tinydb': Starting task run...\n[2020-04-13 00:02:37,326] INFO - prefect.TaskRunner | Task 'problem': Starting task run...\n[2020-04-13 00:02:37,354] INFO - prefect.TaskRunner | Task 'target': finished task run for task with final state: 'Success'\n[2020-04-13 00:02:37,380] INFO - prefect.TaskRunner | Task 'extract_problematic_features': Starting task run...\n[2020-04-13 00:02:37,388] INFO - prefect.TaskRunner | Task 'extract_nan_features': Starting task run...\n[2020-04-13 00:02:37,400] INFO - prefect.TaskRunner | Task 'problem': finished task run for task with final state: 'Success'\n[2020-04-13 00:02:37,447] INFO - prefect.TaskRunner | Task 'extract_problematic_features': finished task run for task with final state: 'Success'\n[2020-04-13 00:02:37,475] INFO - prefect.TaskRunner | Task 'extract_nan_features': finished task run for task with final state: 'Success'\n[2020-04-13 00:02:37,533] INFO - prefect.TaskRunner | Task 'extract_undefined_features': Starting task run...\n[2020-04-13 00:02:37,542] INFO - prefect.TaskRunner | Task 'extract_undefined_features': finished task run for task with final state: 'Success'\n[2020-04-13 00:02:37,567] INFO - prefect.TaskRunner | Task 'fit_transform_missing_indicator': Starting task run...\n[2020-04-13 00:02:37,584] INFO - prefect.TaskRunner | Task 'extract_numeric_features': Starting task run...\n['Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Embarked']\n[3 8]\n['missing_Age', 'missing_Embarked']\n[2020-04-13 00:02:37,591] INFO - prefect.TaskRunner | Task 'recreate_tinydb': finished task run for task with final state: 'Success'\n[2020-04-13 00:02:37,593] INFO - prefect.TaskRunner | Task 'extract_categorical_features': Starting task run...\n[2020-04-13 00:02:37,609] INFO - prefect.TaskRunner | Task 'fit_transform_missing_indicator': finished task run for task with final state: 'Success'\n[2020-04-13 00:02:37,620] INFO - prefect.TaskRunner | Task 'extract_numeric_features': finished task run for task with final state: 'Success'\n[2020-04-13 00:02:37,650] INFO - prefect.TaskRunner | Task 'extract_categorical_features': finished task run for task with final state: 'Success'\n[2020-04-13 00:02:37,659] INFO - prefect.TaskRunner | Task 'extract_train_valid_split': Starting task run...\n[2020-04-13 00:02:37,670] INFO - prefect.TaskRunner | Task 'extract_train_valid_split': finished task run for task with final state: 'Success'\n[2020-04-13 00:02:37,695] INFO - prefect.TaskRunner | Task 'extract_train_data': Starting task run...\n[2020-04-13 00:02:37,702] INFO - prefect.TaskRunner | Task 'extract_valid_data': Starting task run...\n[2020-04-13 00:02:37,709] INFO - prefect.TaskRunner | Task 'extract_train_data': finished task run for task with final state: 'Success'\n[2020-04-13 00:02:37,716] INFO - prefect.TaskRunner | Task 'extract_valid_data': finished task run for task with final state: 'Success'\n[2020-04-13 00:02:37,760] INFO - prefect.TaskRunner | Task 'fit_categorical_imputer': Starting task run...\n[2020-04-13 00:02:37,760] INFO - prefect.TaskRunner | Task 'fit_target_transformer': Starting task run...\n[2020-04-13 00:02:37,762] INFO - prefect.TaskRunner | Task 'fit_numeric_imputer': Starting task run...\n[2020-04-13 00:02:37,774] INFO - prefect.TaskRunner | Task 'fit_target_transformer': finished task run for task with final state: 'Success'\n[2020-04-13 00:02:37,783] INFO - prefect.TaskRunner | Task 'fit_numeric_imputer': finished task run for task with final state: 'Success'\n[2020-04-13 00:02:37,790] INFO - prefect.TaskRunner | Task 'fit_categorical_imputer': finished task run for task with final state: 'Success'\n[2020-04-13 00:02:37,822] INFO - prefect.TaskRunner | Task 'transform_target': Starting task run...\n[2020-04-13 00:02:37,843] INFO - prefect.TaskRunner | Task 'impute_numeric_df': Starting task run...\n[2020-04-13 00:02:37,846] INFO - prefect.TaskRunner | Task 'impute_numeric_df': Starting task run...\n[2020-04-13 00:02:37,852] INFO - prefect.TaskRunner | Task 'transform_target': Starting task run...\n[2020-04-13 00:02:37,863] INFO - prefect.TaskRunner | Task 'transform_target': finished task run for task with final state: 'Success'\n[2020-04-13 00:02:37,873] INFO - prefect.TaskRunner | Task 'impute_numeric_df': finished task run for task with final state: 'Success'\n[2020-04-13 00:02:37,882] INFO - prefect.TaskRunner | Task 'impute_numeric_df': finished task run for task with final state: 'Success'\n[2020-04-13 00:02:37,896] INFO - prefect.TaskRunner | Task 'transform_target': finished task run for task with final state: 'Success'\n[2020-04-13 00:02:37,902] INFO - prefect.TaskRunner | Task 'transform_categorical_data': Starting task run...\n[2020-04-13 00:02:37,914] INFO - prefect.TaskRunner | Task 'transform_categorical_data': Starting task run...\n[2020-04-13 00:02:37,937] INFO - prefect.TaskRunner | Task 'fit_yeo_johnson_transformer': Starting task run...\n[2020-04-13 00:02:37,945] INFO - prefect.TaskRunner | Task 'transform_categorical_data': finished task run for task with final state: 'Success'\n[2020-04-13 00:02:37,956] INFO - prefect.TaskRunner | Task 'transform_categorical_data': finished task run for task with final state: 'Success'\n[2020-04-13 00:02:37,975] INFO - prefect.TaskRunner | Task 'fit_target_encoder': Starting task run...\n[2020-04-13 00:02:38,020] INFO - prefect.TaskRunner | Task 'fit_yeo_johnson_transformer': finished task run for task with final state: 'Success'\n[2020-04-13 00:02:38,064] INFO - prefect.TaskRunner | Task 'transform_yeo_johnson_transformer': Starting task run...\n[2020-04-13 00:02:38,075] INFO - prefect.TaskRunner | Task 'transform_yeo_johnson_transformer': Starting task run...\n[2020-04-13 00:02:38,090] INFO - prefect.TaskRunner | Task 'transform_yeo_johnson_transformer': finished task run for task with final state: 'Success'\n[2020-04-13 00:02:38,101] INFO - prefect.TaskRunner | Task 'transform_yeo_johnson_transformer': finished task run for task with final state: 'Success'\n[2020-04-13 00:02:38,112] INFO - prefect.TaskRunner | Task 'fit_target_encoder': finished task run for task with final state: 'Success'\n[2020-04-13 00:02:38,139] INFO - prefect.TaskRunner | Task 'target_encoder_transform': Starting task run...\n[2020-04-13 00:02:38,149] INFO - prefect.TaskRunner | Task 'target_encoder_transform': Starting task run...\n[2020-04-13 00:02:38,171] INFO - prefect.TaskRunner | Task 'target_encoder_transform': finished task run for task with final state: 'Success'\n[2020-04-13 00:02:38,196] INFO - prefect.TaskRunner | Task 'merge_transformed_data': Starting task run...\n[2020-04-13 00:02:38,198] INFO - prefect.TaskRunner | Task 'target_encoder_transform': finished task run for task with final state: 'Success'\n[2020-04-13 00:02:38,206] INFO - prefect.TaskRunner | Task 'merge_transformed_data': finished task run for task with final state: 'Success'\n[2020-04-13 00:02:38,223] INFO - prefect.TaskRunner | Task 'merge_transformed_data': Starting task run...\n[2020-04-13 00:02:38,232] INFO - prefect.TaskRunner | Task 'merge_transformed_data': finished task run for task with final state: 'Success'\n[2020-04-13 00:02:38,248] INFO - prefect.TaskRunner | Task 'fit_hbos_transformer': Starting task run...\n[2020-04-13 00:02:38,257] INFO - prefect.TaskRunner | Task 'fit_hbos_transformer': finished task run for task with final state: 'Success'\n[2020-04-13 00:02:38,275] INFO - prefect.TaskRunner | Task 'hbos_transform': Starting task run...\n[2020-04-13 00:02:38,288] INFO - prefect.TaskRunner | Task 'hbos_transform': Starting task run...\n[2020-04-13 00:02:38,296] INFO - prefect.TaskRunner | Task 'hbos_transform': finished task run for task with final state: 'Success'\n[2020-04-13 00:02:38,304] INFO - prefect.TaskRunner | Task 'hbos_transform': finished task run for task with final state: 'Success'\n[2020-04-13 00:02:38,324] INFO - prefect.TaskRunner | Task 'merge_hbos_df': Starting task run...\n[2020-04-13 00:02:38,332] INFO - prefect.TaskRunner | Task 'merge_hbos_df': finished task run for task with final state: 'Success'\n[2020-04-13 00:02:38,345] INFO - prefect.TaskRunner | Task 'merge_hbos_df': Starting task run...\n[2020-04-13 00:02:38,356] INFO - prefect.TaskRunner | Task 'merge_hbos_df': finished task run for task with final state: 'Success'\n[2020-04-13 00:02:38,370] INFO - prefect.TaskRunner | Task 'save_data': Starting task run...\n[2020-04-13 00:02:38,387] INFO - prefect.TaskRunner | Task 'save_data': Starting task run...\n[2020-04-13 00:02:38,399] INFO - prefect.TaskRunner | Task 'save_data': finished task run for task with final state: 'Success'\n[2020-04-13 00:02:38,408] INFO - prefect.TaskRunner | Task 'save_data': finished task run for task with final state: 'Success'\n[2020-04-13 00:02:40,389] INFO - prefect.FlowRunner | Flow run SUCCESS: all reference tasks succeeded\n"
    }
   ],
   "source": [
    "from ml_flow import data_cleaning_flow\n",
    "executor = DaskExecutor()\n",
    "data_cleaner = data_cleaning_flow.run(\n",
    "    input_data= input_df, \n",
    "    problem=\"binary classification\", \n",
    "    target = \"Survived\", \n",
    "    features = \"infer\",\n",
    "    executor=executor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slotnames__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_result',\n",
       " 'cached_inputs',\n",
       " 'children',\n",
       " 'color',\n",
       " 'context',\n",
       " 'deserialize',\n",
       " 'is_cached',\n",
       " 'is_failed',\n",
       " 'is_finished',\n",
       " 'is_looped',\n",
       " 'is_mapped',\n",
       " 'is_meta_state',\n",
       " 'is_pending',\n",
       " 'is_queued',\n",
       " 'is_retrying',\n",
       " 'is_running',\n",
       " 'is_scheduled',\n",
       " 'is_skipped',\n",
       " 'is_submitted',\n",
       " 'is_successful',\n",
       " 'message',\n",
       " 'parents',\n",
       " 'result',\n",
       " 'serialize']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(flow_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Flow(\"data_visualization\") as flow:\n",
    "    transformed_train_df = pd.read_feather(\"transformed_train.df\")\n",
    "    transformed_valid_df = pd.read_feather(\"transformed_valid.df\")\n",
    "    svd = fit_svd(transformed_train_df)\n",
    "    svd_train = svd_transform(svd, transformed_train_df, \"transformed_train_df\",tinydb)\n",
    "    svd_valid = svd_transform(svd, transformed_valid_df, \"transformed_valid_df\",tinydb)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Flow(\"meta_model\") as flow:\n",
    "    transformed_train_df = pd.read_feather(\"transformed_train.df\")\n",
    "    transformed_valid_df = pd.read_feather(\"transformed_valid.df\")\n",
    "    \n",
    "    meta = MetaModel(problem=\"regression\", db=tinydb)\n",
    "    meta.default_models()\n",
    "    models = meta.models\n",
    "    fit_models = fit_model.map(\n",
    "        model=models,\n",
    "        train_data=unmapped(transformed_train_df),\n",
    "        target=unmapped(transformed_train_target),\n",
    "        problem=unmapped(problem),\n",
    "    )\n",
    "    predict_models = predict_model.map(\n",
    "        model=fit_models, valid_data=unmapped(transformed_valid_df),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#flow.visualize(flow_state=flow_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tinydb import TinyDB, Query\n",
    "db = TinyDB(\"db.json\")\n",
    "db.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = Query()\n",
    "r = db.search(q.chunk == \"svdname\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__and__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__invert__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__or__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_generate_test',\n",
       " '_path',\n",
       " '_prepare_test',\n",
       " '_test',\n",
       " 'all',\n",
       " 'any',\n",
       " 'exists',\n",
       " 'hashval',\n",
       " 'matches',\n",
       " 'one_of',\n",
       " 'search',\n",
       " 'test']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(q.chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "typing.Any"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flow._sorted_tasks()[38]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__and__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__floordiv__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__mifflin__',\n",
       " '__mod__',\n",
       " '__module__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__or__',\n",
       " '__pow__',\n",
       " '__radd__',\n",
       " '__rand__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rfloordiv__',\n",
       " '__rmod__',\n",
       " '__rmul__',\n",
       " '__ror__',\n",
       " '__rpow__',\n",
       " '__rsub__',\n",
       " '__rtruediv__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slotnames__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__truediv__',\n",
       " '__weakref__',\n",
       " 'auto_generated',\n",
       " 'bind',\n",
       " 'cache_for',\n",
       " 'cache_key',\n",
       " 'cache_validator',\n",
       " 'checkpoint',\n",
       " 'copy',\n",
       " 'inputs',\n",
       " 'is_equal',\n",
       " 'is_not_equal',\n",
       " 'log_stdout',\n",
       " 'logger',\n",
       " 'map',\n",
       " 'max_retries',\n",
       " 'name',\n",
       " 'not_',\n",
       " 'or_',\n",
       " 'outputs',\n",
       " 'result_handler',\n",
       " 'retry_delay',\n",
       " 'run',\n",
       " 'serialize',\n",
       " 'set_dependencies',\n",
       " 'set_downstream',\n",
       " 'set_upstream',\n",
       " 'skip_on_upstream_skip',\n",
       " 'slug',\n",
       " 'state_handlers',\n",
       " 'tags',\n",
       " 'timeout',\n",
       " 'trigger']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(flow._sorted_tasks()[38])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "nteract": {
   "version": "0.22.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}