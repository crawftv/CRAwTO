{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext blackcellmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-04-11T23:02:42.759Z",
     "iopub.status.busy": "2020-04-11T23:02:42.689Z",
     "iopub.status.idle": "2020-04-11T23:02:52.706Z",
     "shell.execute_reply": "2020-04-11T23:02:52.781Z"
    }
   },
   "outputs": [],
   "source": [
    "from prefect import Flow, Parameter, unmapped\n",
    "import pandas as pd\n",
    "from prefect.engine.executors import DaskExecutor\n",
    "from meta_model import MetaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = pd.read_csv(\"../data/house-prices-advanced-regression-techniques/train.csv\")\n",
    "test= pd.read_csv(\"../data/house-prices-advanced-regression-techniques/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ml_flow import *\n",
    "\n",
    "with Flow(\"data_cleaning\") as flow:\n",
    "    input_data = Parameter(\"input_data\")\n",
    "    problem, target, features = (\n",
    "        Parameter(\"problem\"),\n",
    "        Parameter(\"target\"),\n",
    "        Parameter(\"features\"),\n",
    "    )\n",
    "    tinydb = recreate_tinydb()\n",
    "    nan_features = extract_nan_features(input_data)\n",
    "    problematic_features = extract_problematic_features(input_data)\n",
    "    undefined_features = extract_undefined_features(\n",
    "        input_data, features, target, nan_features, problematic_features\n",
    "    )\n",
    "    input_data_with_missing = fit_transform_missing_indicator(\n",
    "        input_data, undefined_features\n",
    "    )\n",
    "\n",
    "    train_valid_split = extract_train_valid_split(\n",
    "        input_data=input_data_with_missing, problem=problem, target=target\n",
    "    )\n",
    "    train_data = extract_train_data(train_valid_split)\n",
    "    valid_data = extract_valid_data(train_valid_split)\n",
    "    numeric_features = extract_numeric_features(input_data, undefined_features)\n",
    "    categorical_features = extract_categorical_features(input_data, undefined_features)\n",
    "\n",
    "    # numeric columns work\n",
    "    numeric_imputer = fit_numeric_imputer(train_data, numeric_features)\n",
    "    imputed_train_numeric_df = impute_numeric_df(\n",
    "        numeric_imputer, train_data, numeric_features\n",
    "    )\n",
    "    imputed_valid_numeric_df = impute_numeric_df(\n",
    "        numeric_imputer, valid_data, numeric_features\n",
    "    )\n",
    "\n",
    "    yeo_johnson_transformer = fit_yeo_johnson_transformer(imputed_train_numeric_df)\n",
    "    yeo_johnson_train_transformed = transform_yeo_johnson_transformer(\n",
    "        imputed_train_numeric_df, yeo_johnson_transformer\n",
    "    )\n",
    "    yeo_johnson_valid_transformed = transform_yeo_johnson_transformer(\n",
    "        imputed_valid_numeric_df, yeo_johnson_transformer\n",
    "    )\n",
    "\n",
    "    # categorical columns work\n",
    "    categorical_imputer = fit_categorical_imputer(train_data, categorical_features)\n",
    "    imputed_train_categorical_df = transform_categorical_data(\n",
    "        train_data, categorical_features, categorical_imputer\n",
    "    )\n",
    "    imputed_valid_categorical_df = transform_categorical_data(\n",
    "        valid_data, categorical_features, categorical_imputer\n",
    "    )\n",
    "\n",
    "    target_transformer = fit_target_transformer(problem, target, train_data)\n",
    "    transformed_train_target = transform_target(\n",
    "        problem, target, train_data, target_transformer\n",
    "    )\n",
    "    transformed_valid_target = transform_target(\n",
    "        problem, target, valid_data, target_transformer\n",
    "    )\n",
    "\n",
    "    target_encoder_transformer = fit_target_encoder(\n",
    "        imputed_train_categorical_df, transformed_train_target\n",
    "    )\n",
    "    target_encoded_train_df = target_encoder_transform(\n",
    "        target_encoder_transformer, imputed_train_categorical_df\n",
    "    )\n",
    "    target_encoded_valid_df = target_encoder_transform(\n",
    "        target_encoder_transformer, imputed_valid_categorical_df\n",
    "    )\n",
    "\n",
    "    # merge_data\n",
    "    transformed_train_df = merge_transformed_data(\n",
    "        target_encoded_train_df, yeo_johnson_train_transformed,\n",
    "    )\n",
    "    transformed_valid_df = merge_transformed_data(\n",
    "        target_encoded_valid_df, yeo_johnson_valid_transformed,\n",
    "    )\n",
    "\n",
    "    # outlierness\n",
    "    hbos_transformer = fit_hbos_transformer(transformed_train_df)\n",
    "    hbos_transform_train_data = hbos_transform(transformed_train_df, hbos_transformer)\n",
    "    hbos_transform_valid_data = hbos_transform(transformed_valid_df, hbos_transformer)\n",
    "\n",
    "    # merge outlierness\n",
    "    transformed_train_df = merge_hbos_df(\n",
    "        transformed_train_df, hbos_transform_train_data\n",
    "    )\n",
    "    transformed_valid_df = merge_hbos_df(\n",
    "        transformed_valid_df, hbos_transform_valid_data\n",
    "    )\n",
    "    save_data(transformed_train_df, \"transformed_train.df\",)\n",
    "    save_data(transformed_valid_df, \"transformed_valid.df\",)\n",
    "    \n",
    "    #dimensionality reduction\n",
    "    svd = fit_svd(transformed_train_df)\n",
    "    svd_train = svd_transform(svd, transformed_train_df, \"transformed_train_df\",tinydb)\n",
    "    svd_valid = svd_transform(svd, transformed_valid_df, \"transformed_valid_df\",tinydb)\n",
    "    \n",
    "\n",
    "    # models\n",
    "    meta = MetaModel(problem=\"regression\", db=tinydb)\n",
    "    meta.default_models()\n",
    "    models = meta.models\n",
    "    fit_models = fit_model.map(\n",
    "        model=models,\n",
    "        train_data=unmapped(transformed_train_df),\n",
    "        target=unmapped(transformed_train_target),\n",
    "        problem=unmapped(problem),\n",
    "    )\n",
    "    predict_models = predict_model.map(\n",
    "        model=fit_models, valid_data=unmapped(transformed_valid_df),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-04-12 23:04:42,048] INFO - prefect.FlowRunner | Beginning Flow run for 'data_cleaning'\n",
      "[2020-04-12 23:04:42,052] INFO - prefect.FlowRunner | Starting flow run.\n",
      "[2020-04-12 23:04:42,149] INFO - prefect.TaskRunner | Task 'recreate_tinydb': Starting task run...\n",
      "[2020-04-12 23:04:42,205] INFO - prefect.TaskRunner | Task 'target': Starting task run...\n",
      "[2020-04-12 23:04:42,226] INFO - prefect.TaskRunner | Task 'problem': Starting task run...\n",
      "[2020-04-12 23:04:42,293] INFO - prefect.TaskRunner | Task 'features': Starting task run...\n",
      "[2020-04-12 23:04:42,330] INFO - prefect.TaskRunner | Task 'input_data': Starting task run...\n",
      "[2020-04-12 23:04:42,347] INFO - prefect.TaskRunner | Task 'problem': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:04:42,360] INFO - prefect.TaskRunner | Task 'target': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:04:42,387] INFO - prefect.TaskRunner | Task 'features': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:04:42,393] INFO - prefect.TaskRunner | Task 'input_data': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:04:42,408] INFO - prefect.TaskRunner | Task 'recreate_tinydb': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:04:42,560] INFO - prefect.TaskRunner | Task 'extract_problematic_features': Starting task run...\n",
      "[2020-04-12 23:04:42,569] INFO - prefect.TaskRunner | Task 'extract_nan_features': Starting task run...\n",
      "[2020-04-12 23:04:42,578] INFO - prefect.TaskRunner | Task 'extract_problematic_features': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:04:42,599] INFO - prefect.TaskRunner | Task 'extract_nan_features': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:04:42,618] INFO - prefect.TaskRunner | Task 'extract_undefined_features': Starting task run...\n",
      "[2020-04-12 23:04:42,626] INFO - prefect.TaskRunner | Task 'extract_undefined_features': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:04:42,732] INFO - prefect.TaskRunner | Task 'extract_categorical_features': Starting task run...\n",
      "[2020-04-12 23:04:42,736] INFO - prefect.TaskRunner | Task 'fit_transform_missing_indicator': Starting task run...\n",
      "[2020-04-12 23:04:42,807] INFO - prefect.TaskRunner | Task 'extract_numeric_features': Starting task run...\n",
      "['MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual', 'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual', 'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold', 'SaleType', 'SaleCondition']\n",
      "[ 2 23 24 28 29 30 31 33 40 55 56 57 60 61]\n",
      "['missing_LotFrontage', 'missing_MasVnrType', 'missing_MasVnrArea', 'missing_BsmtQual', 'missing_BsmtCond', 'missing_BsmtExposure', 'missing_BsmtFinType1', 'missing_BsmtFinType2', 'missing_Electrical', 'missing_GarageType', 'missing_GarageYrBlt', 'missing_GarageFinish', 'missing_GarageQual', 'missing_GarageCond']\n",
      "[2020-04-12 23:04:42,853] INFO - prefect.TaskRunner | Task 'fit_transform_missing_indicator': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:04:42,875] INFO - prefect.TaskRunner | Task 'extract_train_valid_split': Starting task run...\n",
      "[2020-04-12 23:04:42,890] INFO - prefect.TaskRunner | Task 'extract_train_valid_split': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:04:42,905] INFO - prefect.TaskRunner | Task 'extract_categorical_features': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:04:42,947] INFO - prefect.TaskRunner | Task 'extract_valid_data': Starting task run...\n",
      "[2020-04-12 23:04:42,948] INFO - prefect.TaskRunner | Task 'extract_train_data': Starting task run...\n",
      "[2020-04-12 23:04:42,963] INFO - prefect.TaskRunner | Task 'extract_valid_data': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:04:42,964] INFO - prefect.TaskRunner | Task 'extract_numeric_features': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:04:42,971] INFO - prefect.TaskRunner | Task 'extract_train_data': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:04:43,004] INFO - prefect.TaskRunner | Task 'fit_numeric_imputer': Starting task run...\n",
      "[2020-04-12 23:04:43,020] INFO - prefect.TaskRunner | Task 'fit_categorical_imputer': Starting task run...\n",
      "[2020-04-12 23:04:43,023] INFO - prefect.TaskRunner | Task 'fit_target_transformer': Starting task run...\n",
      "[2020-04-12 23:04:43,038] INFO - prefect.TaskRunner | Task 'fit_numeric_imputer': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:04:43,069] INFO - prefect.TaskRunner | Task 'impute_numeric_df': Starting task run...\n",
      "[2020-04-12 23:04:43,087] INFO - prefect.TaskRunner | Task 'impute_numeric_df': Starting task run...\n",
      "[2020-04-12 23:04:43,114] INFO - prefect.TaskRunner | Task 'impute_numeric_df': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:04:43,116] INFO - prefect.TaskRunner | Task 'impute_numeric_df': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:04:43,150] INFO - prefect.TaskRunner | Task 'fit_target_transformer': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:04:43,160] INFO - prefect.TaskRunner | Task 'fit_yeo_johnson_transformer': Starting task run...\n",
      "[2020-04-12 23:04:43,186] INFO - prefect.TaskRunner | Task 'transform_target': Starting task run...\n",
      "[2020-04-12 23:04:43,209] INFO - prefect.TaskRunner | Task 'fit_categorical_imputer': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:04:43,210] INFO - prefect.TaskRunner | Task 'transform_target': Starting task run...\n",
      "[2020-04-12 23:04:43,217] INFO - prefect.TaskRunner | Task 'transform_target': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:04:43,251] INFO - prefect.TaskRunner | Task 'transform_categorical_data': Starting task run...\n",
      "[2020-04-12 23:04:43,252] INFO - prefect.TaskRunner | Task 'transform_categorical_data': Starting task run...\n",
      "[2020-04-12 23:04:43,262] INFO - prefect.TaskRunner | Task 'transform_target': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:04:43,278] INFO - prefect.TaskRunner | Task 'transform_categorical_data': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:04:43,293] INFO - prefect.TaskRunner | Task 'transform_categorical_data': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:04:43,311] INFO - prefect.TaskRunner | Task 'fit_target_encoder': Starting task run...\n",
      "[2020-04-12 23:04:43,978] INFO - prefect.TaskRunner | Task 'fit_target_encoder': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:04:44,011] INFO - prefect.TaskRunner | Task 'target_encoder_transform': Starting task run...\n",
      "[2020-04-12 23:04:44,012] INFO - prefect.TaskRunner | Task 'target_encoder_transform': Starting task run...\n",
      "[2020-04-12 23:04:44,210] INFO - prefect.TaskRunner | Task 'target_encoder_transform': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:04:44,227] INFO - prefect.TaskRunner | Task 'target_encoder_transform': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:04:44,235] INFO - prefect.TaskRunner | Task 'fit_yeo_johnson_transformer': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:04:44,267] INFO - prefect.TaskRunner | Task 'transform_yeo_johnson_transformer': Starting task run...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-04-12 23:04:44,270] INFO - prefect.TaskRunner | Task 'transform_yeo_johnson_transformer': Starting task run...\n",
      "[2020-04-12 23:04:44,279] INFO - prefect.TaskRunner | Task 'transform_yeo_johnson_transformer': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:04:44,298] INFO - prefect.TaskRunner | Task 'merge_transformed_data': Starting task run...\n",
      "[2020-04-12 23:04:44,306] INFO - prefect.TaskRunner | Task 'merge_transformed_data': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:04:44,316] INFO - prefect.TaskRunner | Task 'transform_yeo_johnson_transformer': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:04:44,333] INFO - prefect.TaskRunner | Task 'merge_transformed_data': Starting task run...\n",
      "[2020-04-12 23:04:44,342] INFO - prefect.TaskRunner | Task 'merge_transformed_data': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:04:44,359] INFO - prefect.TaskRunner | Task 'fit_hbos_transformer': Starting task run...\n",
      "[2020-04-12 23:04:44,381] INFO - prefect.TaskRunner | Task 'fit_hbos_transformer': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:04:44,413] INFO - prefect.TaskRunner | Task 'hbos_transform': Starting task run...\n",
      "[2020-04-12 23:04:44,415] INFO - prefect.TaskRunner | Task 'hbos_transform': Starting task run...\n",
      "[2020-04-12 23:04:44,424] INFO - prefect.TaskRunner | Task 'hbos_transform': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:04:44,433] INFO - prefect.TaskRunner | Task 'hbos_transform': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:04:44,455] INFO - prefect.TaskRunner | Task 'merge_hbos_df': Starting task run...\n",
      "[2020-04-12 23:04:44,469] INFO - prefect.TaskRunner | Task 'merge_hbos_df': Starting task run...\n",
      "[2020-04-12 23:04:44,477] INFO - prefect.TaskRunner | Task 'merge_hbos_df': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:04:44,485] INFO - prefect.TaskRunner | Task 'merge_hbos_df': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:04:44,526] INFO - prefect.TaskRunner | Task 'fit_model': Starting task run...\n",
      "[2020-04-12 23:04:44,528] INFO - prefect.TaskRunner | Task 'save_data': Starting task run...\n",
      "[2020-04-12 23:04:44,547] INFO - prefect.TaskRunner | Task 'fit_svd': Starting task run...\n",
      "[2020-04-12 23:04:44,557] INFO - prefect.TaskRunner | Task 'save_data': Starting task run...\n",
      "[2020-04-12 23:04:44,638] INFO - prefect.TaskRunner | Task 'fit_svd': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:04:44,657] INFO - prefect.TaskRunner | Task 'save_data': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:04:44,667] INFO - prefect.TaskRunner | Task 'save_data': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:04:44,743] INFO - prefect.TaskRunner | Task 'fit_model[3]': Starting task run...\n",
      "[2020-04-12 23:04:44,755] INFO - prefect.TaskRunner | Task 'fit_model[2]': Starting task run...\n",
      "[2020-04-12 23:04:44,783] INFO - prefect.TaskRunner | Task 'fit_model[0]': Starting task run...\n",
      "[2020-04-12 23:04:44,783] INFO - prefect.TaskRunner | Task 'fit_model[4]': Starting task run...\n",
      "[2020-04-12 23:04:44,789] INFO - prefect.TaskRunner | Task 'fit_model[1]': Starting task run...\n",
      "[2020-04-12 23:04:44,795] INFO - prefect.TaskRunner | Task 'fit_model[5]': Starting task run...\n",
      "[2020-04-12 23:04:44,806] INFO - prefect.TaskRunner | Task 'fit_model[2]': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:04:44,821] INFO - prefect.TaskRunner | Task 'fit_model[0]': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:04:44,835] INFO - prefect.TaskRunner | Task 'fit_model[1]': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:04:44,842] INFO - prefect.TaskRunner | Task 'fit_model[3]': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:04:44,859] INFO - prefect.TaskRunner | Task 'fit_model[4]': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:04:44,880] INFO - prefect.TaskRunner | Task 'fit_model[6]': Starting task run...\n",
      "[2020-04-12 23:04:44,899] INFO - prefect.TaskRunner | Task 'svd_transform': Starting task run...\n",
      "[2020-04-12 23:04:44,912] INFO - prefect.TaskRunner | Task 'svd_transform': Starting task run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\projects\\crawto\\.venv\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "E:\\projects\\crawto\\crawto\\meta_model.py:79: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self.model.fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-04-12 23:04:45,046] INFO - prefect.TaskRunner | Task 'svd_transform': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:04:45,066] INFO - prefect.TaskRunner | Task 'svd_transform': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:04:45,167] INFO - prefect.TaskRunner | Task 'fit_model[5]': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:04:45,437] INFO - prefect.TaskRunner | Task 'fit_model[6]': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:04:45,452] INFO - prefect.TaskRunner | Task 'fit_model': finished task run for task with final state: 'Mapped'\n",
      "[2020-04-12 23:04:45,475] INFO - prefect.TaskRunner | Task 'predict_model': Starting task run...\n",
      "[2020-04-12 23:04:45,651] INFO - prefect.TaskRunner | Task 'predict_model[4]': Starting task run...\n",
      "[2020-04-12 23:04:45,652] INFO - prefect.TaskRunner | Task 'predict_model[1]': Starting task run...\n",
      "[2020-04-12 23:04:45,652] INFO - prefect.TaskRunner | Task 'predict_model[3]': Starting task run...\n",
      "[2020-04-12 23:04:45,654] INFO - prefect.TaskRunner | Task 'predict_model[2]': Starting task run...\n",
      "[2020-04-12 23:04:45,662] INFO - prefect.TaskRunner | Task 'predict_model[0]': Starting task run...\n",
      "[2020-04-12 23:04:45,668] INFO - prefect.TaskRunner | Task 'predict_model[5]': Starting task run...\n",
      "[2020-04-12 23:04:45,677] INFO - prefect.TaskRunner | Task 'predict_model[4]': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:04:45,686] INFO - prefect.TaskRunner | Task 'predict_model[1]': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:04:45,699] INFO - prefect.TaskRunner | Task 'predict_model[3]': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:04:45,702] INFO - prefect.TaskRunner | Task 'predict_model[2]': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:04:45,710] INFO - prefect.TaskRunner | Task 'predict_model[0]': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:04:45,719] INFO - prefect.TaskRunner | Task 'predict_model[5]': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:04:45,750] INFO - prefect.TaskRunner | Task 'predict_model[6]': Starting task run...\n",
      "[2020-04-12 23:04:45,772] INFO - prefect.TaskRunner | Task 'predict_model[6]': finished task run for task with final state: 'Success'\n",
      "[2020-04-12 23:04:45,788] INFO - prefect.TaskRunner | Task 'predict_model': finished task run for task with final state: 'Mapped'\n",
      "[2020-04-12 23:04:47,799] INFO - prefect.FlowRunner | Flow run SUCCESS: all reference tasks succeeded\n"
     ]
    }
   ],
   "source": [
    "executor = DaskExecutor()\n",
    "flow_state = flow.run(\n",
    "    input_data= input_df, \n",
    "    problem=\"regression\", \n",
    "    target = \"SalePrice\", \n",
    "    features = \"infer\",\n",
    "    executor=executor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#flow.visualize(flow_state=flow_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tinydb import TinyDB, Query\n",
    "db = TinyDB(\"db.json\")\n",
    "db.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = Query()\n",
    "r = db.search(q.chunk == \"svdname\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__and__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__invert__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__or__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_generate_test',\n",
       " '_path',\n",
       " '_prepare_test',\n",
       " '_test',\n",
       " 'all',\n",
       " 'any',\n",
       " 'exists',\n",
       " 'hashval',\n",
       " 'matches',\n",
       " 'one_of',\n",
       " 'search',\n",
       " 'test']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(q.chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "typing.Any"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flow._sorted_tasks()[38]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__and__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__floordiv__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__mifflin__',\n",
       " '__mod__',\n",
       " '__module__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__or__',\n",
       " '__pow__',\n",
       " '__radd__',\n",
       " '__rand__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rfloordiv__',\n",
       " '__rmod__',\n",
       " '__rmul__',\n",
       " '__ror__',\n",
       " '__rpow__',\n",
       " '__rsub__',\n",
       " '__rtruediv__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slotnames__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__truediv__',\n",
       " '__weakref__',\n",
       " 'auto_generated',\n",
       " 'bind',\n",
       " 'cache_for',\n",
       " 'cache_key',\n",
       " 'cache_validator',\n",
       " 'checkpoint',\n",
       " 'copy',\n",
       " 'inputs',\n",
       " 'is_equal',\n",
       " 'is_not_equal',\n",
       " 'log_stdout',\n",
       " 'logger',\n",
       " 'map',\n",
       " 'max_retries',\n",
       " 'name',\n",
       " 'not_',\n",
       " 'or_',\n",
       " 'outputs',\n",
       " 'result_handler',\n",
       " 'retry_delay',\n",
       " 'run',\n",
       " 'serialize',\n",
       " 'set_dependencies',\n",
       " 'set_downstream',\n",
       " 'set_upstream',\n",
       " 'skip_on_upstream_skip',\n",
       " 'slug',\n",
       " 'state_handlers',\n",
       " 'tags',\n",
       " 'timeout',\n",
       " 'trigger']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(flow._sorted_tasks()[38])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "nteract": {
   "version": "0.22.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
