{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-04-11T23:02:42.759Z",
     "iopub.status.busy": "2020-04-11T23:02:42.689Z",
     "iopub.status.idle": "2020-04-11T23:02:52.706Z",
     "shell.execute_reply": "2020-04-11T23:02:52.781Z"
    }
   },
   "outputs": [],
   "source": [
    "from prefect import Flow, Parameter, unmapped\n",
    "import pandas as pd\n",
    "from prefect.engine.executors import DaskExecutor\n",
    "from crawto.meta_model import MetaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = pd.read_csv(\"data/house-prices-advanced-regression-techniques/train.csv\")\n",
    "test= pd.read_csv(\"data/house-prices-advanced-regression-techniques/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of crawto.meta_model failed: Traceback (most recent call last):\n",
      "  File \"e:\\projects\\crawto\\.venv\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"e:\\projects\\crawto\\.venv\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 394, in superreload\n",
      "    module = reload(module)\n",
      "  File \"c:\\users\\cwcol\\appdata\\local\\programs\\python\\python38\\lib\\imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"c:\\users\\cwcol\\appdata\\local\\programs\\python\\python38\\lib\\importlib\\__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 604, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 783, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"E:\\projects\\crawto\\crawto\\meta_model.py\", line 170, in <module>\n",
      "    meta = MetaModel(problem, db, use_default_models=True)\n",
      "NameError: name 'db' is not defined\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from crawto.ml_flow import *\n",
    "from tinydb import TinyDB\n",
    "with Flow(\"data_cleaning\") as flow:\n",
    "    input_data = Parameter(\"input_data\")\n",
    "    problem, target, features = (\n",
    "        Parameter(\"problem\"),\n",
    "        Parameter(\"target\"),\n",
    "        Parameter(\"features\"),\n",
    "    )\n",
    "    #tinydb = recreate_tinydb()\n",
    "    nan_features = extract_nan_features(input_data)\n",
    "    problematic_features = extract_problematic_features(input_data)\n",
    "    undefined_features = extract_undefined_features(\n",
    "        input_data, features, target, nan_features, problematic_features\n",
    "    )\n",
    "    input_data_with_missing = fit_transform_missing_indicator(\n",
    "        input_data, undefined_features\n",
    "    )\n",
    "\n",
    "    train_valid_split = extract_train_valid_split(\n",
    "        input_data=input_data_with_missing, problem=problem, target=target\n",
    "    )\n",
    "    train_data = extract_train_data(train_valid_split)\n",
    "    valid_data = extract_valid_data(train_valid_split)\n",
    "    numeric_features = extract_numeric_features(input_data, undefined_features)\n",
    "    categorical_features = extract_categorical_features(input_data, undefined_features)\n",
    "\n",
    "    # numeric columns work\n",
    "    numeric_imputer = fit_numeric_imputer(train_data, numeric_features)\n",
    "    imputed_train_numeric_df = impute_numeric_df(\n",
    "        numeric_imputer, train_data, numeric_features\n",
    "    )\n",
    "    imputed_valid_numeric_df = impute_numeric_df(\n",
    "        numeric_imputer, valid_data, numeric_features\n",
    "    )\n",
    "\n",
    "    yeo_johnson_transformer = fit_yeo_johnson_transformer(imputed_train_numeric_df)\n",
    "    yeo_johnson_train_transformed = transform_yeo_johnson_transformer(\n",
    "        imputed_train_numeric_df, yeo_johnson_transformer\n",
    "    )\n",
    "    yeo_johnson_valid_transformed = transform_yeo_johnson_transformer(\n",
    "        imputed_valid_numeric_df, yeo_johnson_transformer\n",
    "    )\n",
    "\n",
    "    # categorical columns work\n",
    "    categorical_imputer = fit_categorical_imputer(train_data, categorical_features)\n",
    "    imputed_train_categorical_df = transform_categorical_data(\n",
    "        train_data, categorical_features, categorical_imputer\n",
    "    )\n",
    "    imputed_valid_categorical_df = transform_categorical_data(\n",
    "        valid_data, categorical_features, categorical_imputer\n",
    "    )\n",
    "\n",
    "    target_transformer = fit_target_transformer(problem, target, train_data)\n",
    "    transformed_train_target = transform_target(\n",
    "        problem, target, train_data, target_transformer\n",
    "    )\n",
    "    transformed_valid_target = transform_target(\n",
    "        problem, target, valid_data, target_transformer\n",
    "    )\n",
    "\n",
    "    target_encoder_transformer = fit_target_encoder(\n",
    "        imputed_train_categorical_df, transformed_train_target\n",
    "    )\n",
    "    target_encoded_train_df = target_encoder_transform(\n",
    "        target_encoder_transformer, imputed_train_categorical_df\n",
    "    )\n",
    "    target_encoded_valid_df = target_encoder_transform(\n",
    "        target_encoder_transformer, imputed_valid_categorical_df\n",
    "    )\n",
    "\n",
    "    # merge_data\n",
    "    transformed_train_df = merge_transformed_data(\n",
    "        target_encoded_train_df, yeo_johnson_train_transformed,\n",
    "    )\n",
    "    transformed_valid_df = merge_transformed_data(\n",
    "        target_encoded_valid_df, yeo_johnson_valid_transformed,\n",
    "    )\n",
    "\n",
    "    # outlierness\n",
    "    hbos_transformer = fit_hbos_transformer(transformed_train_df)\n",
    "    hbos_transform_train_data = hbos_transform(transformed_train_df, hbos_transformer)\n",
    "    hbos_transform_valid_data = hbos_transform(transformed_valid_df, hbos_transformer)\n",
    "\n",
    "    # merge outlierness\n",
    "    transformed_train_df = merge_hbos_df(\n",
    "        transformed_train_df, hbos_transform_train_data\n",
    "    )\n",
    "    transformed_valid_df = merge_hbos_df(\n",
    "        transformed_valid_df, hbos_transform_valid_data\n",
    "    )\n",
    "    save_data(transformed_train_df, \"transformed_train.df\",)\n",
    "    save_data(transformed_valid_df, \"transformed_valid.df\",)\n",
    "    \n",
    "#     #dimensionality reduction\n",
    "#     svd = fit_svd(transformed_train_df)\n",
    "#     svd_train = svd_transform(svd, transformed_train_df, \"transformed_train_df\",tinydb)\n",
    "#     svd_valid = svd_transform(svd, transformed_valid_df, \"transformed_valid_df\",tinydb)\n",
    "    \n",
    "\n",
    "    # models\n",
    "    meta = MetaModel(problem=\"regression\", db=TinyDB(\"db.json\"))\n",
    "    model_path = meta.models\n",
    "    fit_models = fit_model.map(\n",
    "        model_path=model_path,\n",
    "        train_data=unmapped(transformed_train_df),\n",
    "        target=unmapped(transformed_train_target),\n",
    "        problem=unmapped(problem),\n",
    "    )\n",
    "#     predict_models = predict_model.map(\n",
    "#         model=fit_models, valid_data=unmapped(transformed_valid_df),\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-04-22 20:15:06,750] INFO - prefect.FlowRunner | Beginning Flow run for 'data_cleaning'\n",
      "[2020-04-22 20:15:06,754] INFO - prefect.FlowRunner | Starting flow run.\n",
      "[2020-04-22 20:15:06,844] INFO - prefect.TaskRunner | Task 'target': Starting task run...\n",
      "[2020-04-22 20:15:06,896] INFO - prefect.TaskRunner | Task 'target': finished task run for task with final state: 'Success'\n",
      "[2020-04-22 20:15:06,912] INFO - prefect.TaskRunner | Task 'problem': Starting task run...\n",
      "[2020-04-22 20:15:06,921] INFO - prefect.TaskRunner | Task 'input_data': Starting task run...\n",
      "[2020-04-22 20:15:06,934] INFO - prefect.TaskRunner | Task 'features': Starting task run...\n",
      "[2020-04-22 20:15:06,937] INFO - prefect.TaskRunner | Task 'problem': finished task run for task with final state: 'Success'\n",
      "[2020-04-22 20:15:06,950] INFO - prefect.TaskRunner | Task 'input_data': finished task run for task with final state: 'Success'\n",
      "[2020-04-22 20:15:06,981] INFO - prefect.TaskRunner | Task 'features': finished task run for task with final state: 'Success'\n",
      "[2020-04-22 20:15:07,078] INFO - prefect.TaskRunner | Task 'extract_problematic_features': Starting task run...\n",
      "[2020-04-22 20:15:07,086] INFO - prefect.TaskRunner | Task 'extract_nan_features': Starting task run...\n",
      "[2020-04-22 20:15:07,142] INFO - prefect.TaskRunner | Task 'extract_problematic_features': finished task run for task with final state: 'Success'\n",
      "[2020-04-22 20:15:07,211] INFO - prefect.TaskRunner | Task 'extract_nan_features': finished task run for task with final state: 'Success'\n",
      "[2020-04-22 20:15:07,262] INFO - prefect.TaskRunner | Task 'extract_undefined_features': Starting task run...\n",
      "[2020-04-22 20:15:07,274] INFO - prefect.TaskRunner | Task 'extract_undefined_features': finished task run for task with final state: 'Success'\n",
      "[2020-04-22 20:15:07,307] INFO - prefect.TaskRunner | Task 'fit_transform_missing_indicator': Starting task run...\n",
      "[2020-04-22 20:15:07,322] INFO - prefect.TaskRunner | Task 'extract_numeric_features': Starting task run...\n",
      "[2020-04-22 20:15:07,328] INFO - prefect.TaskRunner | Task 'extract_categorical_features': Starting task run...\n",
      "['MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual', 'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual', 'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold', 'SaleType', 'SaleCondition']\n",
      "[ 2 23 24 28 29 30 31 33 40 55 56 57 60 61]\n",
      "['missing_LotFrontage', 'missing_MasVnrType', 'missing_MasVnrArea', 'missing_BsmtQual', 'missing_BsmtCond', 'missing_BsmtExposure', 'missing_BsmtFinType1', 'missing_BsmtFinType2', 'missing_Electrical', 'missing_GarageType', 'missing_GarageYrBlt', 'missing_GarageFinish', 'missing_GarageQual', 'missing_GarageCond']\n",
      "[2020-04-22 20:15:07,389] INFO - prefect.TaskRunner | Task 'fit_transform_missing_indicator': finished task run for task with final state: 'Success'\n",
      "[2020-04-22 20:15:07,414] INFO - prefect.TaskRunner | Task 'extract_train_valid_split': Starting task run...\n",
      "[2020-04-22 20:15:07,428] INFO - prefect.TaskRunner | Task 'extract_train_valid_split': finished task run for task with final state: 'Success'\n",
      "[2020-04-22 20:15:07,483] INFO - prefect.TaskRunner | Task 'extract_valid_data': Starting task run...\n",
      "[2020-04-22 20:15:07,486] INFO - prefect.TaskRunner | Task 'extract_train_data': Starting task run...\n",
      "[2020-04-22 20:15:07,507] INFO - prefect.TaskRunner | Task 'extract_numeric_features': finished task run for task with final state: 'Success'\n",
      "[2020-04-22 20:15:07,510] INFO - prefect.TaskRunner | Task 'extract_categorical_features': finished task run for task with final state: 'Success'\n",
      "[2020-04-22 20:15:07,511] INFO - prefect.TaskRunner | Task 'extract_valid_data': finished task run for task with final state: 'Success'\n",
      "[2020-04-22 20:15:07,518] INFO - prefect.TaskRunner | Task 'extract_train_data': finished task run for task with final state: 'Success'\n",
      "[2020-04-22 20:15:07,554] INFO - prefect.TaskRunner | Task 'fit_numeric_imputer': Starting task run...\n",
      "[2020-04-22 20:15:07,572] INFO - prefect.TaskRunner | Task 'fit_target_transformer': Starting task run...\n",
      "[2020-04-22 20:15:07,573] INFO - prefect.TaskRunner | Task 'fit_categorical_imputer': Starting task run...\n",
      "[2020-04-22 20:15:07,587] INFO - prefect.TaskRunner | Task 'fit_numeric_imputer': finished task run for task with final state: 'Success'\n",
      "[2020-04-22 20:15:07,625] INFO - prefect.TaskRunner | Task 'impute_numeric_df': Starting task run...\n",
      "[2020-04-22 20:15:07,637] INFO - prefect.TaskRunner | Task 'impute_numeric_df': Starting task run...\n",
      "[2020-04-22 20:15:07,658] INFO - prefect.TaskRunner | Task 'impute_numeric_df': finished task run for task with final state: 'Success'\n",
      "[2020-04-22 20:15:07,667] INFO - prefect.TaskRunner | Task 'impute_numeric_df': finished task run for task with final state: 'Success'\n",
      "[2020-04-22 20:15:07,697] INFO - prefect.TaskRunner | Task 'fit_yeo_johnson_transformer': Starting task run...\n",
      "[2020-04-22 20:15:07,710] INFO - prefect.TaskRunner | Task 'fit_categorical_imputer': finished task run for task with final state: 'Success'\n",
      "[2020-04-22 20:15:07,738] INFO - prefect.TaskRunner | Task 'transform_categorical_data': Starting task run...\n",
      "[2020-04-22 20:15:07,748] INFO - prefect.TaskRunner | Task 'transform_categorical_data': Starting task run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\projects\\crawto\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:2982: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n",
      "e:\\projects\\crawto\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:2982: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n",
      "e:\\projects\\crawto\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:2982: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n",
      "e:\\projects\\crawto\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:2982: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n",
      "e:\\projects\\crawto\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:2982: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-04-22 20:15:07,774] INFO - prefect.TaskRunner | Task 'transform_categorical_data': finished task run for task with final state: 'Success'\n",
      "[2020-04-22 20:15:07,786] INFO - prefect.TaskRunner | Task 'transform_categorical_data': finished task run for task with final state: 'Success'\n",
      "[2020-04-22 20:15:07,799] INFO - prefect.TaskRunner | Task 'fit_target_transformer': finished task run for task with final state: 'Success'\n",
      "[2020-04-22 20:15:07,833] INFO - prefect.TaskRunner | Task 'transform_target': Starting task run...\n",
      "[2020-04-22 20:15:07,835] INFO - prefect.TaskRunner | Task 'transform_target': Starting task run...\n",
      "[2020-04-22 20:15:07,844] INFO - prefect.TaskRunner | Task 'transform_target': finished task run for task with final state: 'Success'\n",
      "[2020-04-22 20:15:07,854] INFO - prefect.TaskRunner | Task 'transform_target': finished task run for task with final state: 'Success'\n",
      "[2020-04-22 20:15:07,872] INFO - prefect.TaskRunner | Task 'fit_target_encoder': Starting task run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\projects\\crawto\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:2982: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n",
      "e:\\projects\\crawto\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:2982: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n",
      "e:\\projects\\crawto\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:2982: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-04-22 20:15:08,595] INFO - prefect.TaskRunner | Task 'fit_target_encoder': finished task run for task with final state: 'Success'\n",
      "[2020-04-22 20:15:08,628] INFO - prefect.TaskRunner | Task 'target_encoder_transform': Starting task run...\n",
      "[2020-04-22 20:15:08,629] INFO - prefect.TaskRunner | Task 'target_encoder_transform': Starting task run...\n",
      "[2020-04-22 20:15:08,797] INFO - prefect.TaskRunner | Task 'fit_yeo_johnson_transformer': finished task run for task with final state: 'Success'\n",
      "[2020-04-22 20:15:08,840] INFO - prefect.TaskRunner | Task 'transform_yeo_johnson_transformer': Starting task run...\n",
      "[2020-04-22 20:15:08,841] INFO - prefect.TaskRunner | Task 'transform_yeo_johnson_transformer': Starting task run...\n",
      "[2020-04-22 20:15:08,860] INFO - prefect.TaskRunner | Task 'transform_yeo_johnson_transformer': finished task run for task with final state: 'Success'\n",
      "[2020-04-22 20:15:08,892] INFO - prefect.TaskRunner | Task 'transform_yeo_johnson_transformer': finished task run for task with final state: 'Success'\n",
      "[2020-04-22 20:15:08,899] INFO - prefect.TaskRunner | Task 'target_encoder_transform': finished task run for task with final state: 'Success'\n",
      "[2020-04-22 20:15:08,929] INFO - prefect.TaskRunner | Task 'merge_transformed_data': Starting task run...\n",
      "[2020-04-22 20:15:08,937] INFO - prefect.TaskRunner | Task 'target_encoder_transform': finished task run for task with final state: 'Success'\n",
      "[2020-04-22 20:15:08,951] INFO - prefect.TaskRunner | Task 'merge_transformed_data': finished task run for task with final state: 'Success'\n",
      "[2020-04-22 20:15:08,965] INFO - prefect.TaskRunner | Task 'merge_transformed_data': Starting task run...\n",
      "[2020-04-22 20:15:08,975] INFO - prefect.TaskRunner | Task 'merge_transformed_data': finished task run for task with final state: 'Success'\n",
      "[2020-04-22 20:15:08,995] INFO - prefect.TaskRunner | Task 'fit_hbos_transformer': Starting task run...\n",
      "[2020-04-22 20:15:09,021] INFO - prefect.TaskRunner | Task 'fit_hbos_transformer': finished task run for task with final state: 'Success'\n",
      "[2020-04-22 20:15:09,059] INFO - prefect.TaskRunner | Task 'hbos_transform': Starting task run...\n",
      "[2020-04-22 20:15:09,062] INFO - prefect.TaskRunner | Task 'hbos_transform': Starting task run...\n",
      "[2020-04-22 20:15:09,073] INFO - prefect.TaskRunner | Task 'hbos_transform': finished task run for task with final state: 'Success'\n",
      "[2020-04-22 20:15:09,083] INFO - prefect.TaskRunner | Task 'hbos_transform': finished task run for task with final state: 'Success'\n",
      "[2020-04-22 20:15:09,119] INFO - prefect.TaskRunner | Task 'merge_hbos_df': Starting task run...\n",
      "[2020-04-22 20:15:09,123] INFO - prefect.TaskRunner | Task 'merge_hbos_df': Starting task run...\n",
      "[2020-04-22 20:15:09,132] INFO - prefect.TaskRunner | Task 'merge_hbos_df': finished task run for task with final state: 'Success'\n",
      "[2020-04-22 20:15:09,140] INFO - prefect.TaskRunner | Task 'merge_hbos_df': finished task run for task with final state: 'Success'\n",
      "[2020-04-22 20:15:09,166] INFO - prefect.TaskRunner | Task 'save_data': Starting task run...\n",
      "[2020-04-22 20:15:09,184] INFO - prefect.TaskRunner | Task 'save_data': Starting task run...\n",
      "[2020-04-22 20:15:09,190] INFO - prefect.TaskRunner | Task 'fit_model': Starting task run...\n",
      "[2020-04-22 20:15:09,229] INFO - prefect.TaskRunner | Task 'fit_model[0]': Starting task run...\n",
      "[2020-04-22 20:15:09,250] INFO - prefect.TaskRunner | Task 'save_data': finished task run for task with final state: 'Success'\n",
      "[2020-04-22 20:15:09,264] INFO - prefect.TaskRunner | Task 'save_data': finished task run for task with final state: 'Success'\n",
      "[2020-04-22 20:15:09,307] INFO - prefect.TaskRunner | Task 'fit_model[0]': finished task run for task with final state: 'Success'\n",
      "[2020-04-22 20:15:09,317] INFO - prefect.TaskRunner | Task 'fit_model': finished task run for task with final state: 'Mapped'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\projects\\crawto\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:474: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0, tolerance: 0.0\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-04-22 20:15:11,346] INFO - prefect.FlowRunner | Flow run SUCCESS: all reference tasks succeeded\n"
     ]
    }
   ],
   "source": [
    "executor = DaskExecutor()\n",
    "flow_state = flow.run(\n",
    "    input_data= input_df, \n",
    "    problem=\"regression\", \n",
    "    target = \"SalePrice\", \n",
    "    features = \"infer\",\n",
    "    executor=executor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#flow.visualize(flow_state=flow_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinydb import TinyDB, Query\n",
    "db = TinyDB(\"db.json\")\n",
    "db.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = Query()\n",
    "r = db.search(q.chunk == \"svdname\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(q.chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow._sorted_tasks()[38]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(flow._sorted_tasks()[38])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "nteract": {
   "version": "0.22.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
